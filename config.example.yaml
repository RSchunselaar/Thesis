llm:
  provider: openai # disabled | openai
  model: gpt-5-mini # for openai provider
  # For GPT‑5 family keep provider defaults; do not set temperature unless using non‑GPT‑5 models.
  # temperature: 0.0
  # max_tokens: 800

# OpenAI settings (used when provider: openai)
openai:
  base_url: https://api.openai.com

runtime:
  egress: true # thesis default: no‑egress (enable per experiment as needed)
  sqlite_path: ./out/runlog.sqlite

privacy:
  log_prompts: true # true to store prompts/responses in SQLite
  redact_paths: false
  redact_ips: false
  redact_emails: false

parsing:
  include_ext: [".sh", ".bash", ".ksh", ".bat", ".cmd", ".ps1", ".pl", ".py"]

agents:
  reader_hints: false # when true, prompts the Reader to infer path-like env vars (conservative)
